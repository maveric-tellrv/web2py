(dp1
S'output'
p2
S"<type 'exceptions.UnicodeDecodeError'> 'utf8' codec can't decode byte 0xe2 in position 3: unexpected end of data"
p3
sS'layer'
p4
S'/home/rovyas/Documents/web2py/web2py/applications/pluralsight/controllers/priority.py'
p5
sS'code'
p6
S'<code object <module> at 0x7f5f331bccb0, file "/home/rovyas/Documents/web2py/web2py/applications/pluralsight/controllers/priority.py", line 4>'
p7
sS'snapshot'
p8
(dp9
sS'traceback'
p10
S'Traceback (most recent call last):\n  File "/home/rovyas/Documents/web2py/web2py/gluon/restricted.py", line 219, in restricted\n    exec(ccode, environment)\n  File "/home/rovyas/Documents/web2py/web2py/applications/pluralsight/controllers/priority.py", line 231, in <module>\n  File "/home/rovyas/Documents/web2py/web2py/gluon/globals.py", line 414, in <lambda>\n    self._caller = lambda f: f()\n  File "/home/rovyas/Documents/web2py/web2py/applications/pluralsight/controllers/priority.py", line 57, in test\n    word_sent= word_tokenize(sentence.lower())\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/__init__.py", line 128, in word_tokenize\n    sentences = [text] if preserve_line else sent_tokenize(text, language)\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/__init__.py", line 95, in sent_tokenize\n    return tokenizer.tokenize(text)\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1237, in tokenize\n    return list(self.sentences_from_text(text, realign_boundaries))\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1285, in sentences_from_text\n    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1276, in span_tokenize\n    return [(sl.start, sl.stop) for sl in slices]\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1316, in _realign_boundaries\n    for sl1, sl2 in _pair_iter(slices):\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 313, in _pair_iter\n    for el in it:\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1291, in _slices_from_text\n    if self.text_contains_sentbreak(context):\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1337, in text_contains_sentbreak\n    for t in self._annotate_tokens(self._tokenize_words(text)):\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1472, in _annotate_second_pass\n    for t1, t2 in _pair_iter(tokens):\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 312, in _pair_iter\n    prev = next(it)\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 581, in _annotate_first_pass\n    for aug_tok in tokens:\n  File "/usr/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 546, in _tokenize_words\n    for line in plaintext.split(\'\\n\'):\n  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode\n    return codecs.utf_8_decode(input, errors, True)\nUnicodeDecodeError: \'utf8\' codec can\'t decode byte 0xe2 in position 3: unexpected end of data\n'
p11
s.